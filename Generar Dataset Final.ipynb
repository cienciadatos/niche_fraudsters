{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2WHv5foHqpnh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18678,
     "status": "ok",
     "timestamp": 1680256664716,
     "user": {
      "displayName": "Jorge López Fresco",
      "userId": "18362417498933160085"
     },
     "user_tz": -120
    },
    "id": "2WHv5foHqpnh",
    "outputId": "07354860-64a1-4a35-eebd-bab698d38972"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3db9b6",
   "metadata": {},
   "source": [
    "## Cargar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4fe3da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone \"https://github.com/cienciadatos/niche_fraudsters.git\"\n",
    "#!unzip \"niche_fraudsters/data_fraude.zip\"\n",
    "#!unzip \"niche_fraudsters/df_one_hot.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57b9d90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TRAIN  = \"X_train.csv\"\n",
    "DATA_Y      = \"Y_train.csv\"\n",
    "DATA_TEST   = \"X_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0de0ffe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_OH_TRAIN = \"df_one_hot_train.csv\"\n",
    "DF_OH_TEST  = \"df_one_hot_test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UjFvdd2N7WLA",
   "metadata": {
    "id": "UjFvdd2N7WLA"
   },
   "source": [
    "## Importar Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1977cc0",
   "metadata": {
    "id": "d1977cc0"
   },
   "outputs": [],
   "source": [
    "# Librerías Básicas\n",
    "# ==============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Eliminar warnings\n",
    "# ==============================================================================\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "czwyYPBUEiQs",
   "metadata": {
    "id": "czwyYPBUEiQs"
   },
   "source": [
    "## Funciones Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bY6kKkmH761z",
   "metadata": {
    "id": "bY6kKkmH761z"
   },
   "outputs": [],
   "source": [
    "def limpiar_txt_items(df):\n",
    "    \"\"\"Elimina espacios, comas, caracteres raros de las variables itemX con el\n",
    "    fin de unificar valores y eliminar duplicados.\n",
    "    \"\"\"\n",
    "    df.iloc[:,1:25] = df.iloc[:,1:25].replace(r'[^0-9a-zA-Z ]', '', \n",
    "                        regex=True).replace(r'\\s+',' ',regex=True)\n",
    "    return df\n",
    "\n",
    "def data_to_pandas(DATA_TRAIN, DATA_Y):\n",
    "    \"\"\"Generamos dataset de pandas con los csv y unimos el X_train con el \n",
    "    Y_train, que contiene la etiqueta de clase (fraud_flag). Devuelve\n",
    "    el dataset en pandas.DataFrame.\n",
    "    \"\"\"\n",
    "    x_train = pd.read_csv(DATA_TRAIN, sep=\",\")\n",
    "    y_train = pd.read_csv(DATA_Y, sep=\",\")\n",
    "    y_train = y_train.drop('index', axis=1)\n",
    "    df = x_train.merge(y_train)\n",
    "    df = limpiar_txt_items(df)\n",
    "    return df\n",
    "\n",
    "def lista_transacciones_vcalc(df):\n",
    "    \"\"\"Crear una lista de diccionarios para cada fila del dataframe.\n",
    "    Devuelve una lista de transacciones.\n",
    "    \"\"\"\n",
    "    list_trans = []\n",
    "    for index, row in df.iterrows():\n",
    "        precio = []\n",
    "        nb_pp = []\n",
    "        nb_items = int(row[f'Nb_of_items'])\n",
    "        if nb_items > 24: nb_items = 24 # los que tienen más de 24 se dejan a 24.\n",
    "        fraud = row['fraud_flag']\n",
    "        for i in range(1,nb_items+1):\n",
    "            precio.append(row[f'cash_price{i}'])\n",
    "            nb_pp.append(int(row[f'Nbr_of_prod_purchas{i}']))\n",
    "        transaccion = {\n",
    "            'id': row['ID'],\n",
    "            'num_items_dist': nb_items,\n",
    "            'sum_items_total': sum(nb_pp),\n",
    "            'precio_total': sum(precio),\n",
    "            'max_num_prods_item': max(nb_pp),\n",
    "            'precio_max_item': max(precio),\n",
    "            'dif_precio_min_max':abs(max(precio)-min(precio)),\n",
    "            'precio_unit_item_mas_comprado': precio[nb_pp.index(max(nb_pp))]/max(nb_pp),\n",
    "            'apple_prod': row['apple_prod'],\n",
    "            'computers_prod': row['computers_prod'],\n",
    "            'warranty_prod': row['warranty_prod'],\n",
    "            'fulfilment_prod': row['fulfilment_prod'],\n",
    "            'fraud_flag': fraud\n",
    "        }\n",
    "        list_trans.append(transaccion)\n",
    "    return list_trans\n",
    "\n",
    "def lista_transacciones_vcalc_test(df):\n",
    "    \"\"\"Crear una lista de diccionarios para cada fila del dataframe.\n",
    "    Devuelve una lista de transacciones.\n",
    "    \"\"\"\n",
    "    list_trans = []\n",
    "    for index, row in df.iterrows():\n",
    "        # Crear una lista de tuplas para cada artículo y su precio\n",
    "        precio = []\n",
    "        nb_pp = []\n",
    "        nb_items = int(row[f'Nb_of_items'])\n",
    "        if nb_items > 24: nb_items = 24 # los que tienen más de 24 se dejan a 24.\n",
    "        for i in range(1,nb_items+1):\n",
    "            precio.append(row[f'cash_price{i}'])\n",
    "            nb_pp.append(int(row[f'Nbr_of_prod_purchas{i}']))\n",
    "        transaccion = {\n",
    "            'id': row['ID'],\n",
    "            'num_items_dist': nb_items,\n",
    "            'sum_items_total': sum(nb_pp),\n",
    "            'precio_total': sum(precio),\n",
    "            'max_num_prods_item': max(nb_pp),\n",
    "            'precio_max_item': max(precio),\n",
    "            'dif_precio_min_max':abs(max(precio)-min(precio)),\n",
    "            'precio_unit_item_mas_comprado': precio[nb_pp.index(max(nb_pp))]/max(nb_pp),\n",
    "            'apple_prod': row['apple_prod'],\n",
    "            'computers_prod': row['computers_prod'],\n",
    "            'warranty_prod': row['warranty_prod'],\n",
    "            'fulfilment_prod': row['fulfilment_prod']\n",
    "        }\n",
    "        list_trans.append(transaccion)\n",
    "    return list_trans\n",
    "\n",
    "def data_to_csv(df_one_hot, nombre):\n",
    "    \"\"\"Genera un csv con el dataset one_hot_encoder.\"\"\"\n",
    "    df_one_hot.to_csv(nombre+'.csv',sep=\",\",header=True,index=False)\n",
    "    \n",
    "def genera_prod(df_train,prod,col_ini,col_fin):\n",
    "    dx = df_train\n",
    "    d_model = dx.iloc[:,col_ini:col_fin+1]\n",
    "    d_model['ID'] = dx.ID\n",
    "    d_model['Nb_items'] = dx.Nb_of_items\n",
    "    list_prod = []\n",
    "    for i,row in d_model.iterrows():\n",
    "        num_items = int(row['Nb_items'])\n",
    "        if num_items > 24: num_items = 24\n",
    "        fila = row.iloc[:num_items]\n",
    "        if not all(fila.isnull()):\n",
    "            if any(x for x in fila.values if prod.lower() in x.lower()) == True:\n",
    "                list_prod.append((row['ID'],True))\n",
    "                continue\n",
    "        list_prod.append((row['ID'],False))\n",
    "    dx[prod+'_prod'] = pd.DataFrame(list_prod, \n",
    "                        columns=['ID',prod+'_prod']).drop('ID',axis=1)\n",
    "    return dx\n",
    "\n",
    "def prec_mayor(x):\n",
    "    if x <= 600:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def nb_max_menor_8(x):\n",
    "    if x <= 8:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def generar_probf(DF_OH_TRAIN, DF_OH_TEST, df_vcalc_train, df_vcalc_test):\n",
    "\n",
    "    df = pd.read_csv(DF_OH_TRAIN)\n",
    "    df = df.set_index('id')\n",
    "    dt = pd.read_csv(DF_OH_TEST)\n",
    "    dt = dt.set_index('id')\n",
    "    \n",
    "    dt = dt.reindex(columns = df.columns, fill_value=0)\n",
    "    df = df.drop('Nb_of_items', axis=1)\n",
    "    dt = dt.drop('Nb_of_items', axis=1)\n",
    "\n",
    "    # Identificar los patrones de duplicados sin contar la columna 'fraud_flag'\n",
    "    columnas = df.columns.tolist()\n",
    "    columnas.remove('fraud_flag')\n",
    "    patrones_duplicados = df.duplicated(subset=columnas, keep=False)\n",
    "\n",
    "    # Filtrar el DataFrame original para obtener solo las filas duplicadas\n",
    "    filas_duplicadas = df[patrones_duplicados]\n",
    "\n",
    "    # Obtener los patrones únicos sin la columna 'fraud_flag'\n",
    "    patrones_unicos = filas_duplicadas.drop_duplicates(subset=columnas)\n",
    "\n",
    "    # TRAIN ##########\n",
    "    df['probf'] = 0.5\n",
    "    \n",
    "    # Recorrer los patrones únicos y actualizar la columna 'probf' en todas las \n",
    "    # filas que cumplan ese patrón\n",
    "    cont_nf, cont_f, cont_mix = 0, 0, 0\n",
    "    for _, patron in patrones_unicos.iterrows():\n",
    "        mask = (df[columnas] == patron[columnas]).all(axis=1)\n",
    "        support1 = (df.loc[mask, 'fraud_flag'] == 1).sum() / (df.loc[mask,'fraud_flag'].notna().sum())\n",
    "        if support1 == 0: cont_nf+=1\n",
    "        elif support1 == 1: cont_f+=1\n",
    "        else: cont_mix+=1\n",
    "        df.loc[mask, 'probf'] = support1\n",
    "    \n",
    "    #print(cont_nf, cont_f, cont_mix)\n",
    "    \n",
    "    df['probf'] = df['probf'].fillna(0.5)\n",
    "    df_vcalc_train['probf'] = df.reindex(df_vcalc_train.set_index('id').index)['probf'].values\n",
    "    \n",
    "    # TEST ##########\n",
    "    # Inicializar la columna 'probf' en el DataFrame de prueba\n",
    "    df_test['probf'] = 0.5\n",
    "\n",
    "    # Recorrer los patrones únicos y actualizar la columna 'probf' \n",
    "    #en el DataFrame de prueba\n",
    "    for _, patron in patrones_unicos.iterrows():\n",
    "        # Crear una máscara booleana para identificar las filas en el DataFrame de prueba \n",
    "        #que cumplen el patrón\n",
    "        mask = (dt[columnas] == patron[columnas]).all(axis=1)\n",
    "        # Obtener el valor de 'probf' del DataFrame original para el primer valor no nulo \n",
    "        #en las filas que cumplen el patrón\n",
    "        probf = df.loc[df[columnas].eq(patron[columnas]).all(axis=1), \n",
    "                       'probf'].dropna().iloc[0]\n",
    "        # Actualizar el valor de 'probf' en el DataFrame de prueba\n",
    "        dt.loc[mask, 'probf'] = probf\n",
    "\n",
    "    # Llenar los valores faltantes en la columna 'probf' del DataFrame de prueba con 0.5\n",
    "    dt['probf'] = dt['probf'].fillna(0.5)\n",
    "    df_vcalc_test['probf'] = dt.reindex(df_vcalc_test.set_index('id').index)['probf'].values\n",
    "    \n",
    "    return df_vcalc_train, df_vcalc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7899100",
   "metadata": {},
   "source": [
    "## Crear Dataset Final (Fraud 3)\n",
    "\n",
    "Vamos a modificar el dataset \"Fraud 2\" y ampliarlo, apostando más por el precio y el nº de productos. Las variables que se crearán son las siguientes:\n",
    "\n",
    "`id (int)`: Id de la transacción. \\\n",
    "`num_items_dist (int)`: Nº de productos distintos en la transacción. \\\n",
    "`sum_items_total (int)`: Nº de productos en total. \\\n",
    "`precio_total (float)`: Precio total de la transacción. \\\n",
    "`max_num_prods_item (int)`: Nº máximo de productos iguales en una transacción. \\\n",
    "`precio_max_item (float)`: Precio máximo de un producto en una transacción. \\\n",
    "`dif_precio_min_max (float)`: Diferencia entre precio máximo y mínimo. \\\n",
    "`precio_unit_item_mas_comprado (float)`: Precio unitario del item más comprado. \\\n",
    "`precio_mayor_600 (bool)`: False si precio_total <= 600 y True si es > de 600. \\\n",
    "`nb_max_items_menor_8 (bool)`: False si max_num_prods_item > 8 y True si <= 8. \\\n",
    "`nb_items_mayor_20 (bool)`: False si sum_items_total < 20 y True si >= 20. \\\n",
    "`apple_prod (bool)`: False si no incluye apple. True si lo incluye. \\\n",
    "`computer_prod (bool)`: False si no incluye computer. True si lo incluye. \\\n",
    "**`warranty_prod (bool)`: False si no incluye warranty. True si lo incluye.** \\\n",
    "**`fulfilment_prod`:  False si no incluye fulfilment. True si lo incluye.** \\\n",
    "`probf (float)`: Probabilidad de fraude calculada con el confidence. \\\n",
    "`fraud_flag (bool)`: Etiqueta de fraude. 0 si es no fraude y 1 si es fraude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7739ad3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializa los datasets y los prepara\n",
    "# ==============================================================================\n",
    "df_train = data_to_pandas(DATA_TRAIN,DATA_Y)\n",
    "df_test = pd.read_csv(DATA_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccff52ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genera columna Apple Prod\n",
    "# ==============================================================================\n",
    "df_train = genera_prod(df_train,'apple',73,96)\n",
    "df_test = genera_prod(df_test,'apple',73,96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d11a52c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genera columna Computers Prod\n",
    "# ==============================================================================\n",
    "df_train = genera_prod(df_train,'computers',1,24)\n",
    "df_test = genera_prod(df_test,'computers',1,24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8420528c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genera columna Warranty Prod\n",
    "# ==============================================================================\n",
    "df_train = genera_prod(df_train,'warranty',1,24)\n",
    "df_test = genera_prod(df_test,'warranty',1,24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a6829bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genera columna Fulfilment Prod\n",
    "# ==============================================================================\n",
    "df_train = genera_prod(df_train,'fulfilment',1,24)\n",
    "df_test = genera_prod(df_test,'fulfilment',1,24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dNMzL0EmG71-",
   "metadata": {
    "id": "dNMzL0EmG71-"
   },
   "outputs": [],
   "source": [
    "# Genera dataset con Variables Calculadas\n",
    "# ==============================================================================\n",
    "df_final_train = pd.DataFrame(lista_transacciones_vcalc(df_train))\n",
    "df_final_test  = pd.DataFrame(lista_transacciones_vcalc_test(df_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "031ea74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genera columna de Precio > 600\n",
    "# ==============================================================================\n",
    "df_final_train['precio_mayor_600'] = df_final_train['precio_total'].apply(prec_mayor)\n",
    "df_final_test['precio_mayor_600'] = df_final_test['precio_total'].apply(prec_mayor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25fa8b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genera columna de Nb Max Items < 8\n",
    "# ==============================================================================\n",
    "df_final_train['nb_max_items_menor_8'] = df_final_train['max_num_prods_item'].apply(nb_max_menor_8)\n",
    "df_final_test['nb_max_items_menor_8'] = df_final_test['max_num_prods_item'].apply(nb_max_menor_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53421450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar columna con probabilidades de fraude\n",
    "# ==============================================================================\n",
    "df_final_train, df_final_test = generar_probf(DF_OH_TRAIN, DF_OH_TEST, \n",
    "                                        df_final_train,df_final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a983e0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reordenar las columnas de Train\n",
    "# ==============================================================================\n",
    "df_final_train = df_final_train[['id', 'num_items_dist', 'sum_items_total', \n",
    "  'precio_total', 'max_num_prods_item', 'precio_max_item', 'dif_precio_min_max',\n",
    "  'precio_unit_item_mas_comprado', 'precio_mayor_600', 'nb_max_items_menor_8',\n",
    "  'apple_prod', 'computers_prod', 'warranty_prod', 'fulfilment_prod', \n",
    "  'probf', 'fraud_flag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90fd51bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reordenar las columnas de Test\n",
    "# ==============================================================================\n",
    "df_final_test = df_final_test[['id', 'num_items_dist', 'sum_items_total', \n",
    "  'precio_total', 'max_num_prods_item', 'precio_max_item', 'dif_precio_min_max',\n",
    "  'precio_unit_item_mas_comprado', 'precio_mayor_600', 'nb_max_items_menor_8',\n",
    "  'apple_prod', 'computers_prod', 'warranty_prod', 'fulfilment_prod', \n",
    "  'probf']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40cabb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar datasets a csv\n",
    "# ==============================================================================\n",
    "#data_to_csv(df_final_train,\"df_final_train\")\n",
    "#data_to_csv(df_final_test,\"df_final_test\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
